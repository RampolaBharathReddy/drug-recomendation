{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4256a8ac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 118561 samples, validate on 13174 samples\n",
      "Epoch 1/150\n",
      "118561/118561 [==============================] - 37s 308us/sample - loss: 1.0990 - acc: 0.3530 - val_loss: 1.0867 - val_acc: 0.3705\n",
      "Epoch 2/150\n",
      "118561/118561 [==============================] - 39s 331us/sample - loss: 1.0712 - acc: 0.3648 - val_loss: 1.0519 - val_acc: 0.3836\n",
      "Epoch 3/150\n",
      "118561/118561 [==============================] - 38s 324us/sample - loss: 1.0505 - acc: 0.3995 - val_loss: 1.0274 - val_acc: 0.4293\n",
      "Epoch 4/150\n",
      "118561/118561 [==============================] - 39s 328us/sample - loss: 1.0371 - acc: 0.4197 - val_loss: 1.0184 - val_acc: 0.4365\n",
      "Epoch 5/150\n",
      "118561/118561 [==============================] - 39s 331us/sample - loss: 1.0318 - acc: 0.4252 - val_loss: 1.0137 - val_acc: 0.4425\n",
      "Epoch 6/150\n",
      "118561/118561 [==============================] - 39s 328us/sample - loss: 1.0289 - acc: 0.4292 - val_loss: 1.0062 - val_acc: 0.4512\n",
      "Epoch 7/150\n",
      "118561/118561 [==============================] - 38s 319us/sample - loss: 1.0253 - acc: 0.4359 - val_loss: 1.0050 - val_acc: 0.4655\n",
      "Epoch 8/150\n",
      "118561/118561 [==============================] - 40s 337us/sample - loss: 1.0223 - acc: 0.4399 - val_loss: 0.9999 - val_acc: 0.4586\n",
      "Epoch 9/150\n",
      "118561/118561 [==============================] - 155s 1ms/sample - loss: 1.0201 - acc: 0.4444 - val_loss: 0.9993 - val_acc: 0.4564\n",
      "Epoch 10/150\n",
      "118561/118561 [==============================] - 39s 332us/sample - loss: 1.0174 - acc: 0.4457 - val_loss: 0.9883 - val_acc: 0.4660\n",
      "Epoch 11/150\n",
      "118561/118561 [==============================] - 36s 304us/sample - loss: 1.0142 - acc: 0.4474 - val_loss: 0.9825 - val_acc: 0.4674\n",
      "Epoch 12/150\n",
      "118561/118561 [==============================] - 36s 301us/sample - loss: 1.0128 - acc: 0.4514 - val_loss: 0.9828 - val_acc: 0.4727\n",
      "Epoch 13/150\n",
      "118561/118561 [==============================] - 36s 305us/sample - loss: 1.0114 - acc: 0.4502 - val_loss: 0.9772 - val_acc: 0.4708\n",
      "Epoch 14/150\n",
      "118561/118561 [==============================] - 32s 272us/sample - loss: 1.0104 - acc: 0.4503 - val_loss: 0.9762 - val_acc: 0.4732\n",
      "Epoch 15/150\n",
      "118561/118561 [==============================] - 35s 299us/sample - loss: 1.0076 - acc: 0.4521 - val_loss: 0.9685 - val_acc: 0.4843\n",
      "Epoch 16/150\n",
      "118561/118561 [==============================] - 38s 317us/sample - loss: 1.0071 - acc: 0.4514 - val_loss: 0.9667 - val_acc: 0.4762\n",
      "Epoch 17/150\n",
      "118561/118561 [==============================] - 36s 305us/sample - loss: 1.0061 - acc: 0.4512 - val_loss: 0.9753 - val_acc: 0.4692\n",
      "Epoch 18/150\n",
      "118561/118561 [==============================] - 34s 283us/sample - loss: 1.0050 - acc: 0.4534 - val_loss: 0.9605 - val_acc: 0.4820\n",
      "Epoch 19/150\n",
      "118561/118561 [==============================] - 34s 285us/sample - loss: 1.0046 - acc: 0.4505 - val_loss: 0.9632 - val_acc: 0.4765\n",
      "Epoch 20/150\n",
      "118561/118561 [==============================] - 34s 286us/sample - loss: 1.0033 - acc: 0.4525 - val_loss: 0.9745 - val_acc: 0.4759\n",
      "Epoch 21/150\n",
      "118561/118561 [==============================] - 34s 283us/sample - loss: 1.0040 - acc: 0.4542 - val_loss: 0.9661 - val_acc: 0.4750\n",
      "Epoch 22/150\n",
      "118561/118561 [==============================] - 34s 283us/sample - loss: 0.9999 - acc: 0.4542 - val_loss: 0.9551 - val_acc: 0.4862\n",
      "Epoch 23/150\n",
      "118561/118561 [==============================] - 34s 285us/sample - loss: 1.0013 - acc: 0.4530 - val_loss: 0.9553 - val_acc: 0.4753\n",
      "Epoch 24/150\n",
      "118561/118561 [==============================] - 35s 291us/sample - loss: 1.0018 - acc: 0.4531 - val_loss: 0.9679 - val_acc: 0.4695\n",
      "Epoch 25/150\n",
      "118561/118561 [==============================] - 35s 296us/sample - loss: 1.0008 - acc: 0.4545 - val_loss: 0.9602 - val_acc: 0.4842\n",
      "Epoch 26/150\n",
      "118561/118561 [==============================] - 39s 325us/sample - loss: 0.9989 - acc: 0.4562 - val_loss: 0.9598 - val_acc: 0.4784\n",
      "Epoch 27/150\n",
      "118561/118561 [==============================] - 38s 322us/sample - loss: 1.0001 - acc: 0.4578 - val_loss: 0.9603 - val_acc: 0.4823\n",
      "Epoch 28/150\n",
      "118561/118561 [==============================] - 38s 322us/sample - loss: 1.0014 - acc: 0.4557 - val_loss: 0.9597 - val_acc: 0.4775\n",
      "Epoch 29/150\n",
      "118561/118561 [==============================] - 38s 322us/sample - loss: 0.9978 - acc: 0.4557 - val_loss: 0.9517 - val_acc: 0.4857\n",
      "Epoch 30/150\n",
      "118561/118561 [==============================] - 54s 454us/sample - loss: 0.9991 - acc: 0.4557 - val_loss: 0.9465 - val_acc: 0.4928\n",
      "Epoch 31/150\n",
      "118561/118561 [==============================] - 27s 228us/sample - loss: 0.9985 - acc: 0.4582 - val_loss: 0.9624 - val_acc: 0.4760\n",
      "Epoch 32/150\n",
      "118561/118561 [==============================] - 28s 234us/sample - loss: 0.9974 - acc: 0.4595 - val_loss: 0.9584 - val_acc: 0.4871\n",
      "Epoch 33/150\n",
      "118561/118561 [==============================] - 25s 215us/sample - loss: 0.9959 - acc: 0.4602 - val_loss: 0.9573 - val_acc: 0.4812\n",
      "Epoch 34/150\n",
      "118561/118561 [==============================] - 37s 309us/sample - loss: 0.9962 - acc: 0.4579 - val_loss: 0.9537 - val_acc: 0.4813\n",
      "Epoch 35/150\n",
      "118561/118561 [==============================] - 37s 309us/sample - loss: 0.9961 - acc: 0.4583 - val_loss: 0.9544 - val_acc: 0.4905\n",
      "Epoch 36/150\n",
      "118561/118561 [==============================] - 37s 310us/sample - loss: 0.9967 - acc: 0.4588 - val_loss: 0.9515 - val_acc: 0.4869\n",
      "Epoch 37/150\n",
      "118561/118561 [==============================] - 43s 362us/sample - loss: 0.9951 - acc: 0.4597 - val_loss: 0.9593 - val_acc: 0.4756\n",
      "Epoch 38/150\n",
      "118561/118561 [==============================] - 37s 310us/sample - loss: 0.9930 - acc: 0.4640 - val_loss: 0.9481 - val_acc: 0.4853\n",
      "Epoch 39/150\n",
      " 43968/118561 [==========>...................] - ETA: 21s - loss: 0.9945 - acc: 0.4610"
     ]
    }
   ],
   "source": [
    "from tkinter import *\n",
    "import tkinter\n",
    "from tkinter import filedialog\n",
    "import numpy as np\n",
    "from tkinter.filedialog import askopenfilename\n",
    "import pandas as pd \n",
    "from tkinter import simpledialog\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "from tensorflow.keras.models import load_model\n",
    "import seaborn as sns\n",
    "import os \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "main = tkinter.Tk()\n",
    "main.title(\"Multivariate Gait Analysis for Healthy Subjects under Various Walking Conditions\")\n",
    "main.geometry(\"1000x650\")\n",
    "\n",
    "global filename\n",
    "global fnn_model, mlp_model\n",
    "global X_train, y_train, X_test, y_test\n",
    "\n",
    "def upload():\n",
    "    global filename\n",
    "    global dataset\n",
    "    filename = filedialog.askopenfilename(initialdir = \"dataset\")\n",
    "    text.delete('1.0', END)\n",
    "    text.insert(END,filename+' Loaded\\n\\n')\n",
    "    dataset = pd.read_csv(filename)\n",
    "    text.insert(END,str(dataset.head))\n",
    "\n",
    "def preprocess():\n",
    "    global dataset\n",
    "    global X_train, y_train, X_test, y_test\n",
    "    text.delete('1.0', END)\n",
    "    X = dataset.drop(\"condition\", axis=1).values\n",
    "    Y = dataset['condition']\n",
    "    le = LabelEncoder()\n",
    "    Y = le.fit_transform(Y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=0)\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    # Initialize the StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Fit the scaler on the training data and transform both the training and testing data\n",
    "    X_train= scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)  # Use the same scaler instance to transform the test data\n",
    "\n",
    "    text.insert(END,\"\\n\\nTotal Records for training : \"+str(len(X_train))+\"\\n\")\n",
    "    text.insert(END,str(X_train))\n",
    "    text.insert(END,\"\\n\"+str(y_train))\n",
    "    # Assuming y_train is your original target variable\n",
    "    y_train = to_categorical(y_train, num_classes=3)\n",
    "    # Assuming y_test is your original test target variable\n",
    "    y_test= to_categorical(y_test, num_classes=3)\n",
    "def feedforwardneuralnetwork():\n",
    "    global y_test\n",
    "    if os.path.exists('model.h5'):\n",
    "        # Load the existing model\n",
    "        loaded_model = load_model('model.h5')\n",
    "        # Evaluate the model\n",
    "        loss, accuracy = loaded_model.evaluate(X_test, y_test)\n",
    "\n",
    "        # Print the accuracy\n",
    "        print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
    "        # Generate classification report\n",
    "        y_pred = loaded_model.predict(X_test)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "        print(y_pred_classes)\n",
    "        y_test1 = np.argmax(y_test, axis=1)\n",
    "        Accuracy_score=accuracy_score(y_test1, y_pred_classes)\n",
    "        text.insert(END, f\"Neural Accuracy Score: { Accuracy_score}\\n\")\n",
    "        report=classification_report(y_test1, y_pred_classes)\n",
    "        text.insert(END, f\"Neural Network classification_report: {report}\\n\")\n",
    "        # Calculate confusion matrix\n",
    "        cm = confusion_matrix(y_test1, y_pred_classes)\n",
    "        text.insert(END, f\"Neural Network confusion_matrix: {cm}\\n\")\n",
    "        # Plot the confusion matrix as a heatmap\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.set(font_scale=1.2)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.title('Neural network Confusion Matrix')\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        \n",
    "        from tensorflow.keras.models import Sequential\n",
    "        from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "        # Initialize the model\n",
    "        model = Sequential()\n",
    "\n",
    "        # Add layers to the model\n",
    "        model.add(Dense(256, input_dim=X_train.shape[1], activation='relu'))\n",
    "        model.add(Dropout(0.5))  # Adding dropout for regularization\n",
    "\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Dense(32, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Dense(16, activation='selu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        \n",
    "        model.add(Dense(8, activation='selu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        \n",
    "        model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  # Change the loss function to categorical_crossentropy\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train, epochs=150, batch_size=16, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "        # Evaluate the model\n",
    "        accuracy = model.evaluate(X_test, y_test)\n",
    "        print(f'Test Accuracy:',accuracy)\n",
    "        # Save FNN Model\n",
    "        model.save('model.h5')  # Save the Keras model\n",
    "\n",
    "\n",
    "def runMLP():\n",
    "    global mlp_model\n",
    "    global X_train, y_train, X_test, y_test\n",
    "    mlp_model = MLPClassifier(hidden_layer_sizes=(32, 32), activation='relu', max_iter=100)\n",
    "    mlp_model.fit(X_train, y_train)\n",
    "    y_pred = mlp_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    text.insert(END, f\"Accuracy on Test Set (MLP): {accuracy}\\n\")\n",
    "    report=classification_report(y_test, y_pred)\n",
    "    text.insert(END, f\"MLP classification_report: {report}\\n\")\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    text.insert(END, f\"MLP confusion_matrix: {cm}\\n\")\n",
    "    # Plot the confusion matrix as a heatmap\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.set(font_scale=1.2)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('MLP Classifier Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "def close():\n",
    "    main.destroy()\n",
    "\n",
    "font = ('times', 15, 'bold')\n",
    "title = Label(main, text='Multivariate Gait Analysis for Healthy Subjects under Various Walking Conditions', justify=LEFT)\n",
    "title.config(bg='lavender blush', fg='DarkOrchid1')  \n",
    "title.config(font=font)           \n",
    "title.config(height=3, width=120)       \n",
    "title.place(x=100,y=5)\n",
    "title.pack()\n",
    "\n",
    "font1 = ('times', 12, 'bold')\n",
    "uploadButton = Button(main, text=\"Upload Multivariate Gait Dataset\", command=upload)\n",
    "uploadButton.place(x=10,y=100)\n",
    "uploadButton.config(font=font1)  \n",
    "\n",
    "preprocessButton = Button(main, text=\"Preprocess Dataset\", command=preprocess)\n",
    "preprocessButton.place(x=300,y=100)\n",
    "preprocessButton.config(font=font1)\n",
    "\n",
    "FNNButton = Button(main, text=\"Feed Forward Neural Network Algorithm\", command=feedforwardneuralnetwork)\n",
    "FNNButton.place(x=700,y=100)\n",
    "FNNButton.config(font=font1)\n",
    "\n",
    "MLPButton = Button(main, text=\"Run MLP Algorithm\", command=runMLP)\n",
    "MLPButton.place(x=480,y=100)\n",
    "MLPButton.config(font=font1)\n",
    "\n",
    "closeButton = Button(main, text=\"Close Application\", command=close)\n",
    "closeButton.place(x=10,y=200)\n",
    "closeButton.config(font=font1)\n",
    "\n",
    "font1 = ('times', 12, 'bold')\n",
    "text=Text(main,height=20,width=160)\n",
    "scroll=Scrollbar(text)\n",
    "text.configure(yscrollcommand=scroll.set)\n",
    "text.place(x=10,y=250)\n",
    "text.config(font=font1) \n",
    "\n",
    "main.config(bg='light coral')\n",
    "main.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c14fb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
